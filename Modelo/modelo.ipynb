{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>...</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "      <th>y_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>2143</td>\n",
       "      <td>5</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>1506</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  balance  day  duration  campaign  pdays  previous  job_blue-collar  \\\n",
       "0   58     2143    5       261         1     -1         0                0   \n",
       "1   44       29    5       151         1     -1         0                0   \n",
       "2   33        2    5        76         1     -1         0                0   \n",
       "3   47     1506    5        92         1     -1         0                1   \n",
       "4   33        1    5       198         1     -1         0                0   \n",
       "\n",
       "   job_entrepreneur  job_housemaid  ...  month_jun  month_mar  month_may  \\\n",
       "0                 0              0  ...          0          0          1   \n",
       "1                 0              0  ...          0          0          1   \n",
       "2                 1              0  ...          0          0          1   \n",
       "3                 0              0  ...          0          0          1   \n",
       "4                 0              0  ...          0          0          1   \n",
       "\n",
       "   month_nov  month_oct  month_sep  poutcome_other  poutcome_success  \\\n",
       "0          0          0          0               0                 0   \n",
       "1          0          0          0               0                 0   \n",
       "2          0          0          0               0                 0   \n",
       "3          0          0          0               0                 0   \n",
       "4          0          0          0               0                 0   \n",
       "\n",
       "   poutcome_unknown  y_yes  \n",
       "0                 1      0  \n",
       "1                 1      0  \n",
       "2                 1      0  \n",
       "3                 1      0  \n",
       "4                 1      0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Verificar si el archivo existe\n",
    "file_path = '../Limpieza/data_dummies.csv'\n",
    "\n",
    "data = pd.read_csv(file_path, sep=';')\n",
    " \n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45211, 43)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.28753763 0.28562948 0.3059386  0.29916805 0.30192709 0.27186624\n",
      " 0.30437693 0.31541435 0.31276703 0.29598056]\n",
      "Mean cross-validation score: 0.2980605963560075\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Crear el modelo de regresión lineal\n",
    "regression = LinearRegression()\n",
    "\n",
    "# Realizar la validación cruzada\n",
    "scores = cross_val_score(regression, X_train, y_train, cv=10)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean cross-validation score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características seleccionadas: ['duration']\n",
      "Mean Squared Error: 0.09996054524618525\n",
      "Coeficiente de determinación R^2: 0.05777948465198668\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Separar características (X) y variable objetivo (y)\n",
    "X = data.drop(columns=['y_yes'])\n",
    "y = data['y_yes']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar las características (Lasso es sensible a la escala de las variables)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Crear y ajustar el modelo Lasso\n",
    "lasso = Lasso(alpha=0.1)  # Ajusta alpha para controlar la regularización\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Imprimir las características seleccionadas (con coeficiente distinto de cero)\n",
    "selected_features = [feature for feature, coef in zip(X.columns, lasso.coef_) if coef != 0]\n",
    "print(\"Características seleccionadas:\", selected_features)\n",
    "\n",
    "# Evaluar el modelo Lasso\n",
    "y_pred = lasso.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Coeficiente de determinación R^2:\", lasso.score(X_test_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation R^2 scores: [0.05988667 0.05702819 0.05630836 0.05735894 0.05613545 0.05672125\n",
      " 0.05744418 0.05903862 0.06295517 0.06212107]\n",
      "Mean Cross-validation R^2 score: 0.05849978976333855\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Separar características (X) y variable objetivo (y)\n",
    "X = data.drop(columns=['y_yes'])  # Características\n",
    "y = data['y_yes']  # Variable objetivo\n",
    "\n",
    "# Crear un pipeline que incluya el escalado y el modelo Lasso\n",
    "pipeline = make_pipeline(StandardScaler(), Lasso(alpha=0.1))\n",
    "\n",
    "# Definir el objeto KFold para 5 particiones (por ejemplo)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Realizar la validación cruzada\n",
    "scores = cross_val_score(pipeline, X, y, cv=kf, scoring='r2')\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Cross-validation R^2 scores:\", scores)\n",
    "print(\"Mean Cross-validation R^2 score:\", scores.mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.90468819 0.90776377 0.9048883  0.87856669 0.88608715 0.88365406\n",
      " 0.85733245 0.87303694 0.88564477 0.85202389]\n",
      "Mean cross-validation accuracy: 0.8833686200355881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Crear el modelo de regresión logística\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# Realizar la validación cruzada con la métrica de precisión (accuracy)\n",
    "scores = cross_val_score(logistic_regression, X, y, cv=10, scoring='accuracy')\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Cross-validation accuracy scores:\", scores)\n",
    "print(\"Mean cross-validation accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: age, Coeficiente: -0.01703285836807898\n",
      "Variable: balance, Coeficiente: 1.7631351319968e-05\n",
      "Variable: day, Coeficiente: -0.010300898319114715\n",
      "Variable: duration, Coeficiente: 0.0038234833888144575\n",
      "Variable: campaign, Coeficiente: -0.3844342717945095\n",
      "Variable: pdays, Coeficiente: 0.0023113371798994154\n",
      "Variable: previous, Coeficiente: -0.14579819447206896\n",
      "Variable: job_blue-collar, Coeficiente: -0.2884440152805934\n",
      "Variable: job_entrepreneur, Coeficiente: -0.027931949303613538\n",
      "Variable: job_housemaid, Coeficiente: -0.00605384785894319\n",
      "Variable: job_management, Coeficiente: 0.007488035283181514\n",
      "Variable: job_retired, Coeficiente: 0.182535413423583\n",
      "Variable: job_self-employed, Coeficiente: -0.014380571015067544\n",
      "Variable: job_services, Coeficiente: -0.09613022347680289\n",
      "Variable: job_student, Coeficiente: 0.028846413772819376\n",
      "Variable: job_technician, Coeficiente: -0.08324617623427633\n",
      "Variable: job_unemployed, Coeficiente: 0.005016086284404601\n",
      "Variable: job_unknown, Coeficiente: 0.002231427355482808\n",
      "Variable: marital_married, Coeficiente: -0.19417097513274412\n",
      "Variable: marital_single, Coeficiente: -0.15076311887632524\n",
      "Variable: education_secondary, Coeficiente: -0.30265537667519005\n",
      "Variable: education_tertiary, Coeficiente: 0.05329738091402511\n",
      "Variable: education_unknown, Coeficiente: 0.008323877336254129\n",
      "Variable: default_yes, Coeficiente: -0.022429578789657248\n",
      "Variable: housing_yes, Coeficiente: -0.7576636940526585\n",
      "Variable: loan_yes, Coeficiente: -0.2123435658759606\n",
      "Variable: contact_telephone, Coeficiente: 0.06090219978918603\n",
      "Variable: contact_unknown, Coeficiente: -0.49012678518208513\n",
      "Variable: month_aug, Coeficiente: 0.03466106840004107\n",
      "Variable: month_dec, Coeficiente: 0.03371547488448022\n",
      "Variable: month_feb, Coeficiente: -0.025894379889518333\n",
      "Variable: month_jan, Coeficiente: -0.01638298199234478\n",
      "Variable: month_jul, Coeficiente: -0.08716651295763576\n",
      "Variable: month_jun, Coeficiente: -0.0676225064335464\n",
      "Variable: month_mar, Coeficiente: 0.09543247883174585\n",
      "Variable: month_may, Coeficiente: -0.47870063392122236\n",
      "Variable: month_nov, Coeficiente: -0.06385432607100734\n",
      "Variable: month_oct, Coeficiente: 0.1124415622055625\n",
      "Variable: month_sep, Coeficiente: 0.08589776938550607\n",
      "Variable: poutcome_other, Coeficiente: -0.031737658120258805\n",
      "Variable: poutcome_success, Coeficiente: 0.34874327696348256\n",
      "Variable: poutcome_unknown, Coeficiente: -0.4864270705755285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Asegurarse de que el modelo esté ajustado antes de acceder a coef_\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el coeficiente para cada característica\n",
    "coef = logistic_regression.coef_[0]  # .coef_ es una matriz de 2D; [0] selecciona la primera fila\n",
    "variables = X.columns\n",
    "\n",
    "# Imprimir cada variable con su coeficiente\n",
    "for var, c in zip(variables, coef):\n",
    "    print(f\"Variable: {var}, Coeficiente: {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy on test set: 0.8987061815769103\n",
      "\n",
      "Final model summary:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  y_yes   No. Observations:                36168\n",
      "Model:                          Logit   Df Residuals:                    36138\n",
      "Method:                           MLE   Df Model:                           29\n",
      "Date:                Wed, 30 Oct 2024   Pseudo R-squ.:                  0.3374\n",
      "Time:                        12:27:36   Log-Likelihood:                -8603.3\n",
      "converged:                       True   LL-Null:                       -12985.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  -2.4412      0.111    -22.092      0.000      -2.658      -2.225\n",
      "day                     0.0101      0.003      3.590      0.000       0.005       0.016\n",
      "duration                0.0042   7.26e-05     57.990      0.000       0.004       0.004\n",
      "campaign               -0.0911      0.011     -8.059      0.000      -0.113      -0.069\n",
      "job_blue-collar        -0.3229      0.068     -4.754      0.000      -0.456      -0.190\n",
      "job_entrepreneur       -0.3077      0.132     -2.327      0.020      -0.567      -0.049\n",
      "job_housemaid          -0.4842      0.141     -3.436      0.001      -0.760      -0.208\n",
      "job_management         -0.1284      0.066     -1.948      0.051      -0.258       0.001\n",
      "job_services           -0.1885      0.084     -2.251      0.024      -0.353      -0.024\n",
      "job_student             0.3676      0.110      3.336      0.001       0.152       0.584\n",
      "job_technician         -0.1832      0.064     -2.866      0.004      -0.309      -0.058\n",
      "marital_married        -0.2309      0.042     -5.466      0.000      -0.314      -0.148\n",
      "education_secondary     0.1362      0.061      2.229      0.026       0.016       0.256\n",
      "education_tertiary      0.2788      0.072      3.861      0.000       0.137       0.420\n",
      "housing_yes            -0.6895      0.048    -14.350      0.000      -0.784      -0.595\n",
      "loan_yes               -0.4115      0.066     -6.214      0.000      -0.541      -0.282\n",
      "contact_unknown        -1.6821      0.081    -20.741      0.000      -1.841      -1.523\n",
      "month_aug              -0.7015      0.087     -8.097      0.000      -0.871      -0.532\n",
      "month_dec               0.6533      0.191      3.420      0.001       0.279       1.028\n",
      "month_feb              -0.2561      0.101     -2.547      0.011      -0.453      -0.059\n",
      "month_jan              -1.3102      0.136     -9.628      0.000      -1.577      -1.043\n",
      "month_jul              -0.8949      0.085    -10.546      0.000      -1.061      -0.729\n",
      "month_jun               0.4231      0.105      4.029      0.000       0.217       0.629\n",
      "month_mar               1.5575      0.135     11.570      0.000       1.294       1.821\n",
      "month_may              -0.4610      0.081     -5.723      0.000      -0.619      -0.303\n",
      "month_nov              -0.9091      0.093     -9.755      0.000      -1.092      -0.726\n",
      "month_oct               0.8710      0.119      7.312      0.000       0.637       1.104\n",
      "month_sep               0.9047      0.132      6.828      0.000       0.645       1.164\n",
      "poutcome_other          0.3271      0.086      3.802      0.000       0.159       0.496\n",
      "poutcome_success        2.3653      0.073     32.376      0.000       2.222       2.508\n",
      "=======================================================================================\n",
      "\n",
      "Final accuracy on test set: 0.8998120092889528\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Función para entrenar un modelo de regresión logística y calcular el accuracy\n",
    "def train_and_evaluate_logit(X_train, X_test, y_train, y_test):\n",
    "    # Agregar constante al conjunto de entrenamiento\n",
    "    X_train_const = sm.add_constant(X_train)\n",
    "    \n",
    "    # Crear y ajustar el modelo de regresión logística\n",
    "    model = sm.Logit(y_train, X_train_const)\n",
    "    result = model.fit(disp=False)  # disp=False oculta los detalles de ajuste en cada iteración\n",
    "    \n",
    "    # Agregar constante al conjunto de prueba y calcular el accuracy\n",
    "    X_test_const = sm.add_constant(X_test, has_constant='add')\n",
    "    y_pred_prob = result.predict(X_test_const)\n",
    "    y_pred = [1 if p >= 0.5 else 0 for p in y_pred_prob]\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return result, accuracy\n",
    "\n",
    "# Entrenar el modelo inicial para obtener los valores p\n",
    "initial_result, initial_accuracy = train_and_evaluate_logit(X_train, X_test, y_train, y_test)\n",
    "print(\"Initial accuracy on test set:\", initial_accuracy)\n",
    "\n",
    "# Obtener las variables significativas (p < 0.05) en el modelo entrenado\n",
    "significant_vars = initial_result.pvalues[initial_result.pvalues < 0.05].index\n",
    "significant_vars = significant_vars.drop('const', errors='ignore')  # Excluir la constante si está presente\n",
    "\n",
    "# Filtrar el conjunto de datos de entrenamiento y prueba con las variables significativas\n",
    "X_train_significant = X_train[significant_vars]\n",
    "X_test_significant = X_test[significant_vars]\n",
    "\n",
    "# Reentrenar el modelo con las variables significativas\n",
    "final_result, final_accuracy = train_and_evaluate_logit(X_train_significant, X_test_significant, y_train, y_test)\n",
    "print(\"\\nFinal model summary:\")\n",
    "print(final_result.summary())\n",
    "print(\"\\nFinal accuracy on test set:\", final_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'logreg__C': 0.01, 'logreg__l1_ratio': 0.5}\n",
      "Mejor AUC en validación: 0.909784443308347\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91     11966\n",
      "           1       0.42      0.82      0.56      1598\n",
      "\n",
      "    accuracy                           0.85     13564\n",
      "   macro avg       0.70      0.84      0.73     13564\n",
      "weighted avg       0.91      0.85      0.87     13564\n",
      "\n",
      "AUC en el conjunto de prueba: 0.9097860082080703\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Cargar el archivo\n",
    "file_path = '../Limpieza/data_dummies.csv'\n",
    "data = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# Separar variables predictoras y variable de interés\n",
    "X = data.drop(columns=['y_yes'])\n",
    "y = data['y_yes']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Crear un pipeline con estandarización y regresión logística con Elastic Net\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Estandarización de datos\n",
    "    ('logreg', LogisticRegression(penalty='elasticnet', solver='saga', max_iter=10000,class_weight='balanced'))  # Elastic Net\n",
    "])\n",
    "\n",
    "# Definir los hiperparámetros para Elastic Net\n",
    "param_grid = {\n",
    "    'logreg__l1_ratio': [0.1, 0.5, 0.7, 0.9],  # Peso entre L1 y L2 (Elastic Net)\n",
    "    'logreg__C': [0.01, 0.1, 1, 10, 100]  # Inverso de la regularización\n",
    "}\n",
    "\n",
    "# Búsqueda de hiperparámetros\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Resultados del mejor modelo\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor AUC en validación:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"AUC en el conjunto de prueba:\", roc_auc_score(y_test, y_pred_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\python311\\lib\\site-packages (from imbalanced-learn) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\python311\\lib\\site-packages (from imbalanced-learn) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\python311\\lib\\site-packages (from imbalanced-learn) (1.4.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\python311\\lib\\site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python311\\lib\\site-packages (from imbalanced-learn) (3.2.0)\n",
      "Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
      "   ---------------------------------------- 0.0/258.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 258.3/258.3 kB 7.8 MB/s eta 0:00:00\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.12.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Mejores hiperparámetros: {'logreg__C': 0.01, 'logreg__l1_ratio': 0.9}\n",
      "Mejor AUC en validación: 0.9682545597000317\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93     11966\n",
      "           1       0.50      0.46      0.48      1598\n",
      "\n",
      "    accuracy                           0.88     13564\n",
      "   macro avg       0.72      0.70      0.71     13564\n",
      "weighted avg       0.88      0.88      0.88     13564\n",
      "\n",
      "AUC en el conjunto de prueba: 0.8698117758346187\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo\n",
    "file_path = '../Limpieza/data_dummies.csv'\n",
    "data = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# Separar variables predictoras y variable de interés\n",
    "X = data.drop(columns=['y_yes'])\n",
    "y = data['y_yes']\n",
    "\n",
    "# Aplicar SMOTE después de dividir en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Aplicar SMOTE en el conjunto de entrenamiento\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Crear un pipeline con estandarización y regresión logística con Elastic Net\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Estandarización de datos\n",
    "    ('logreg', LogisticRegression(penalty='elasticnet', solver='saga', max_iter=10000))  # Elastic Net\n",
    "])\n",
    "\n",
    "# Definir los hiperparámetros para Elastic Net\n",
    "param_grid = {\n",
    "    'logreg__l1_ratio': [0.1, 0.5, 0.7, 0.9],  # Peso entre L1 y L2 (Elastic Net)\n",
    "    'logreg__C': [0.01, 0.1, 1, 10, 100]  # Inverso de la regularización\n",
    "}\n",
    "\n",
    "# Búsqueda de hiperparámetros\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Resultados del mejor modelo\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor AUC en validación:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"AUC en el conjunto de prueba:\", roc_auc_score(y_test, y_pred_proba))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
